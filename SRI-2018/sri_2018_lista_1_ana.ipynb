{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução à Recuperação de Informações\n",
    "\n",
    "# Lista de exercícios 1\n",
    "\n",
    "## Ana Carolina Wagner G. de Barros\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Carregando as bibliotecas e preparando o ambiente\n",
    "\n",
    "Vamos utilizar a biblioteca NLTK para processamento de linguagem natural. Em seguida vamos importar mais coisas necessárias para o nosso trabalho. Note que estamos baixando a obra completa de Machado de Assis, com a qual iremos alimentar nosso índice. Vamos também baixar o banco de stopwords do NLTK. Stop words são um conjunto de palavras que normalmente carregam baixo conteúdo semântico e portanto não são alvo de buscas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import machado, mac_morpho\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import PortugueseStemmer\n",
    "\n",
    "import string\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/acwgdb/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package machado to /Users/acwgdb/nltk_data...\n",
      "[nltk_data]   Package machado is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('machado')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lendo o texto puro dos livros de Machado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textos = []\n",
    "for i in machado.fileids():\n",
    "    textos.append(machado.raw(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a lista de stopwords em lingua portuguesa para limpeza dos textos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "swu = stopwords.words('portuguese') + list (string.punctuation)\n",
    "stemmer = PortugueseStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Preparando o corpus com e sem *stemming*\n",
    "\n",
    "A técnica de *stemming* consiste em reduzir o termo ao seu radical, removendo afixos e vogais temáticas. Por exemplo, a palavra “frequentemente” após esse processo se torna “frequent”, a palavra “copiar” após esse processo se torna “copi”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sem stemming\n",
    "textos_normal = []\n",
    "for texto in textos:\n",
    "    tlimpo = [token.lower() for token in WordPunctTokenizer().tokenize(texto) if token not in swu]\n",
    "    textos_normal.append(tlimpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Com stemming\n",
    "textos_stem = []\n",
    "for texto in textos_normal:\n",
    "    tlimpo = [stemmer.stem(token) for token in texto]\n",
    "    textos_stem.append(tlimpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conto', 'contos', 'fluminenses', '1870', 'contos', 'fluminenses', 'texto', 'fonte', 'obra', 'completa']\n",
      "['cont', 'cont', 'fluminens', '1870', 'cont', 'fluminens', 'text', 'font', 'obra', 'complet']\n"
     ]
    }
   ],
   "source": [
    "print(textos_normal[0][0:10])\n",
    "print(textos_stem[0][0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Criando os índices invertidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indice_normal = defaultdict(lambda:set([]))\n",
    "for tid,t in enumerate(textos_normal):\n",
    "    for term in t:\n",
    "        indice_normal[term].add(tid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indice_stem = defaultdict(lambda:set([]))\n",
    "for tid,t in enumerate(textos_stem):\n",
    "    for term in t:\n",
    "        indice_stem[term].add(tid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Função de busca\n",
    "\n",
    "O operador segue funcional até outro operador ser sugerido. O operador padrão é o 'or'. \n",
    "\n",
    "Operadores disponíveis: 'and', 'or' e 'not'.\n",
    "\n",
    "Eles são executados nesta mesma sequência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def busca(consulta, indice):\n",
    "    \n",
    "    tokens = WordPunctTokenizer().tokenize(consulta)\n",
    "\n",
    "    resultado = set()\n",
    "    operador = 'or'\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token == 'and':\n",
    "            operador = 'and'\n",
    "            \n",
    "        elif token == 'or':\n",
    "            operador = 'or'\n",
    "        \n",
    "        elif token == 'not':\n",
    "            operador = 'not'\n",
    "            \n",
    "        else:\n",
    "            resultado_temp = indice[token]\n",
    "            if operador == 'and':\n",
    "                resultado = resultado & resultado_temp\n",
    "            \n",
    "            elif operador == 'not':\n",
    "                resultado = resultado - resultado_temp\n",
    "                \n",
    "            else:\n",
    "                resultado = resultado | resultado_temp\n",
    "    \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 1: Truncagem e revocação.\n",
    "\n",
    "Baseando-se no indice invertido construído na prática 1, calcule a diferença de revocação com e sem a utilização de \"stemming\", ou truncagem na construção do índice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precisão:** \"Quantos elementos selecionados são relevantes?\"\n",
    "\n",
    "$$Pre = \\frac{|\\{ \\text{documentos recuperados} \\cap \\text{documentos relevantes} \\}|}{|\\{ \\text{documentos recuperados}\\}|}$$\n",
    "\n",
    "A precisão corresponde ao número de resultados corretos dividido pelo número de todos os resultados retornados.\n",
    "\n",
    "**Revocação:** \"Quantos elementos relevantes foram selecionados?\"\n",
    "\n",
    "$$Rev = \\frac{|\\{ \\text{documentos recuperados} \\cap \\text{documentos relevantes} \\}|}{|\\{ \\text{documentos relevantes}\\}|}$$\n",
    "\n",
    "A revocação corresponde ao número de resultados corretos dividido pelo número de resultados que deveriam ter sido apresentados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/a/ab/Precisão_e_revocação.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PreRev(recuperados, relevantes):\n",
    "    \n",
    "    # precisao \n",
    "    pre = len(recuperados &  relevantes)/len(recuperados)\n",
    "    # revocacao\n",
    "    rev = len(recuperados &  relevantes)/len(relevantes)\n",
    "    \n",
    "    return pre,rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Palavra a ser consultada\n",
    "palavra = 'contos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de Resultados Stemmizado: 219\n",
      "Quantidade de Resultados Não Stemmizado: 74\n"
     ]
    }
   ],
   "source": [
    "# Resultados da busca\n",
    "res_normal = busca(palavra,indice_normal)\n",
    "res_stem = busca(stemmer.stem(palavra), indice_stem)\n",
    "\n",
    "print('Quantidade de Resultados Stemmizado: ' + str(len(res_stem)))\n",
    "\n",
    "print('Quantidade de Resultados Não Stemmizado: ' + str(len(res_normal)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A revocação é calculada como a proporção entre o resultado de stemming com o resultado sem stemming.\n",
    "\n",
    "$$Rev = \\frac{Res_\\text{normal}}{Res_\\text{stem}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão: 1.0\n",
      "Revocação: 0.3378995433789954\n"
     ]
    }
   ],
   "source": [
    "print('Precisão: ' +  str(PreRev(res_normal, res_stem)[0]))\n",
    "print('Revocação: ' + str(PreRev(res_normal, res_stem)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 2: Expansão de consultas\n",
    "Crie grupos de equivalência para alguns termos de busca e calcule a diferença em termos de revocação e, possivelmente precisão, na resposta a consultas expandidas e não expandidas. Dica: use tempos verbais, pluralização, sinônimos, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "termos = ['contos', 'conto', 'contar', 'contando', 'narração', 'narrações'] \n",
    "#termos = ['ator', 'atores','atriz','atrizes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos encontrados sem Stemming:\n",
      " contos: 74\n",
      " conto: 166\n",
      " contar: 128\n",
      " contando: 58\n",
      " narração: 84\n",
      " narrações: 13\n",
      "\n",
      "\n",
      "TOTAL: 201\n"
     ]
    }
   ],
   "source": [
    "res_normal2 = set()\n",
    "\n",
    "print('Documentos encontrados sem Stemming:')\n",
    "for termo in termos:\n",
    "    res = busca(termo, indice_normal)\n",
    "    res_normal2.update(res)\n",
    "    print(' {}: {}'.format(termo, len(res)))\n",
    "print('\\n')\n",
    "print('TOTAL: {}'.format(len(res_normal2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos encontrados sem Stemming:\n",
      " contos: 219\n",
      " conto: 219\n",
      " contar: 219\n",
      " contando: 219\n",
      " narração: 84\n",
      " narrações: 13\n",
      "\n",
      "\n",
      "TOTAL: 221\n"
     ]
    }
   ],
   "source": [
    "res_stem2 = set()\n",
    "\n",
    "print('Documentos encontrados sem Stemming:')\n",
    "for termo in termos:\n",
    "    res = busca(stemmer.stem(termo), indice_stem)\n",
    "    res_stem2.update(res)\n",
    "    print(' {}: {}'.format(termo, len(res)))\n",
    "print('\\n')\n",
    "print('TOTAL: {}'.format(len(res_stem2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão: 1.0\n",
      "Revocação: 0.9095022624434389\n"
     ]
    }
   ],
   "source": [
    "print('Precisão: ' +  str(PreRev(res_normal2, res_stem2)[0]))\n",
    "print('Revocação: ' + str(PreRev(res_normal2, res_stem2)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Houve uma grande melhora na revocação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exercício 3: Verificação ortográfica\n",
    "Implemente uma expansão de consulta por meio da correção ortográfica. Utilize o corretor ortográfico Pyenchant para fazer as correções.\n",
    "\n",
    "Tutorial: https://github.com/rfk/pyenchant/blob/master/website/content/tutorial.rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import enchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dicionario\n",
    "d = enchant.Dict(\"pt_BR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos implementar uma função que checa as palavras de busca e sugere novas palavras se algo estiver errado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def corrige_palavra(palavra):\n",
    "    \n",
    "    if not d.check(palavra):\n",
    "        \n",
    "        print('Você quis dizer: ')\n",
    "        for p in d.suggest(palavra)[:5]:\n",
    "            print('-', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Você quis dizer: \n",
      "- om tos\n",
      "- otos\n",
      "- onos\n",
      "- tontos\n",
      "- contos\n"
     ]
    }
   ],
   "source": [
    "corrige_palavra('ontos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def busca_correta(palavra,ind,dic):\n",
    "\n",
    "    # faz a verificação ortográfica e a busca sobre os termos possíveis\n",
    "    \n",
    "    if not dic.check(palavra):\n",
    "        resultado = set()\n",
    "        for token in dic.suggest(palavra):\n",
    "            resultado = resultado | ind[token]\n",
    "    else:\n",
    "        resultado = ind[termo]\n",
    "        \n",
    "    return resultado\n",
    "\n",
    "def busca2(consulta, indice):\n",
    "    \n",
    "    d = enchant.Dict(\"pt_BR\")\n",
    "    tokens = WordPunctTokenizer().tokenize(consulta)\n",
    "\n",
    "    resultado = set()\n",
    "    operador = 'or'\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token == 'and':\n",
    "            operador = 'and'\n",
    "            \n",
    "        elif token == 'or':\n",
    "            operador = 'or'\n",
    "        \n",
    "        elif token == 'not':\n",
    "            operador = 'not'\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            #resultado_temp = indice[token]\n",
    "            # Caso um termo esteja escrito errado, faz-se a busca sobre todas as correções sugeridas\n",
    "            resultado_temp = busca_correta(token, indice, d)\n",
    "            \n",
    "            if operador == 'and':\n",
    "                resultado = resultado & resultado_temp\n",
    "            \n",
    "            elif operador == 'not':\n",
    "                resultado = resultado - resultado_temp\n",
    "                \n",
    "            else:\n",
    "                resultado = resultado | resultado_temp\n",
    "    \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Palavra a ser consultada\n",
    "palavra = 'ontos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de Resultados Stemmizado: 0\n",
      "Quantidade de Resultados Não Stemmizado: 0\n"
     ]
    }
   ],
   "source": [
    "# Resultados da busca usando a função criada para os exercícios anteriores (busca)\n",
    "res_normal = busca(palavra,indice_normal)\n",
    "res_stem = busca(stemmer.stem(palavra), indice_stem)\n",
    "\n",
    "print('Quantidade de Resultados Stemmizado: ' + str(len(res_stem)))\n",
    "\n",
    "print('Quantidade de Resultados Não Stemmizado: ' + str(len(res_normal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de Resultados Stemmizado: 0\n",
      "Quantidade de Resultados Não Stemmizado: 93\n"
     ]
    }
   ],
   "source": [
    "# Resultados da busca usando a função adaptada que usa a correção ortográfica (busca2)\n",
    "res_normal = busca2(palavra,indice_normal)\n",
    "res_stem = busca2(stemmer.stem(palavra), indice_stem)\n",
    "\n",
    "print('Quantidade de Resultados Stemmizado: ' + str(len(res_stem)))\n",
    "\n",
    "print('Quantidade de Resultados Não Stemmizado: ' + str(len(res_normal)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exercício 4: Consultas por frases\n",
    "Implemente um indice invertido que permita consulta por frases, conforme definido na aula 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "O objetivo é buscar uma frase, exata ou não, dentro de uma coleção de documentos. \n",
    "\n",
    "#### 1. Criando novo indice para consulta por frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textos_limpos = []\n",
    "for texto in textos:\n",
    "    tlimpo = [stemmer.stem(token.lower()) for token in WordPunctTokenizer().tokenize(texto) if token not in swu]\n",
    "    textos_limpos.append(tlimpo)\n",
    "    \n",
    "indice_frase = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for texto_id, texto in enumerate(textos_limpos):\n",
    "    for token_id, token in enumerate(texto):\n",
    "        indice_frase[token][texto_id].append(token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Testando o índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([230])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indice_frase[stemmer.stem(\"Capitu\")].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indice_frase[stemmer.stem(\"Capitu\")][230])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capitu (Capitolina) é uma personagem da obra **Dom Casmurro** de Machado de Assis. Assim, podemos dizer que o documento 230 corresponde a referida obra. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Redefinindo a nova função de busca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxliar da função **busca_frase**: compara a proximidade entre termos de duas listas e devolve a média dos valores quando proximos. Utilziamos a média, pois ela capta os termos que estão próximos, pelo menos boa parte do conjunto de tokens próximos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proximidade_termos(lista1, lista2, distancia):\n",
    "    resultado = []\n",
    "    \n",
    "    for i in lista1:\n",
    "        for j in lista2:\n",
    "            if abs(i-j) <= distancia:\n",
    "                resultado.append(round((i+j)/2))\n",
    "                \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def busca_frase(frase, indice, distancia=1):\n",
    "    \n",
    "    tokens = [stemmer.stem(token.lower()) for token in WordPunctTokenizer().tokenize(frase) if token not in swu]\n",
    "    \n",
    "    # Verificar quais documentos possuem todos os termos\n",
    "    matches = indice[tokens[0]].keys()\n",
    "    \n",
    "    for token in tokens[1:]:\n",
    "        matches = matches & indice[token].keys()    \n",
    "        \n",
    "    # Comparar as posições dentro dos documentos em comum\n",
    "    resultado = defaultdict(list)\n",
    "    \n",
    "    for documento in matches:\n",
    "        \n",
    "        resultado_temp = indice[tokens[0]][documento]\n",
    "        \n",
    "        for token in tokens[1:]:\n",
    "            resultado_temp = proximidade_termos(resultado_temp,indice[token][documento],distancia)\n",
    "            \n",
    "        if resultado_temp:\n",
    "            resultado[documento] = resultado_temp\n",
    "            \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {230: [10018, 10314, 13638, 13700, 13742, 36264, 39560]})"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "busca_frase(\"olhos de ressaca\", indice_frase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De fato, \"olhos de ressaca\" e como Machado de Assis em Dom Casmurro, define os olhos de Capitu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exercício 5: Consulta híbrida.\n",
    "Modifique a solução acima para permitir respostas alternativas caso a frase não retorne resultados. Por exemplo, retornar, documentos que contenham parte da frase, ou uma busca booleana simples combinando as palavras da frase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
